{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook pertaining to text analysis where I seek to find different text analysis metrics of the financial reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>'item 7. management\\'s discussion  analysis  f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>\"item 2. management's discussion  analysis  fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>'item 7. management\\'s discussion  analysis  f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0  \\\n",
       "0  https://www.sec.gov/Archives/edgar/data/3662/0...   \n",
       "1  https://www.sec.gov/Archives/edgar/data/3662/0...   \n",
       "2  https://www.sec.gov/Archives/edgar/data/3662/0...   \n",
       "3  https://www.sec.gov/Archives/edgar/data/3662/0...   \n",
       "4  https://www.sec.gov/Archives/edgar/data/3662/0...   \n",
       "\n",
       "                                                   0    1   2  \n",
       "0  'item 7. management\\'s discussion  analysis  f...  NaN NaN  \n",
       "1  \"item 2. management's discussion  analysis  fi...  NaN NaN  \n",
       "2                                                NaN  NaN NaN  \n",
       "3  'item 7. management\\'s discussion  analysis  f...  NaN NaN  \n",
       "4                                                NaN  NaN NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('corpus.csv')\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analysis of Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data above is a sample of the extracted data that one has to work with. It has already been made free of stopwords during the extraction phase so that ought not be done here. However, first, in order to find sentiment metrics, one has to prepare a positive and negative word dictionary. I am using \"Loughran McDonald Master Dictionary 2018\" for that purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Positive and Negative Word Dictionaries (Lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Superfluous</th>\n",
       "      <th>Interesting</th>\n",
       "      <th>Modal</th>\n",
       "      <th>Irr_Verb</th>\n",
       "      <th>Harvard_IV</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>1.480000e-08</td>\n",
       "      <td>1.240000e-08</td>\n",
       "      <td>3.560000e-06</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.600000e-10</td>\n",
       "      <td>9.730000e-12</td>\n",
       "      <td>9.860000e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4.280000e-10</td>\n",
       "      <td>1.390000e-10</td>\n",
       "      <td>6.230000e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>6.410000e-10</td>\n",
       "      <td>3.160000e-10</td>\n",
       "      <td>9.380000e-08</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>5</td>\n",
       "      <td>7250</td>\n",
       "      <td>3.870000e-07</td>\n",
       "      <td>3.680000e-07</td>\n",
       "      <td>3.370000e-05</td>\n",
       "      <td>914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Sequence Number  Word Count  Word Proportion  \\\n",
       "0   AARDVARK                1         277     1.480000e-08   \n",
       "1  AARDVARKS                2           3     1.600000e-10   \n",
       "2      ABACI                3           8     4.280000e-10   \n",
       "3      ABACK                4          12     6.410000e-10   \n",
       "4     ABACUS                5        7250     3.870000e-07   \n",
       "\n",
       "   Average Proportion       Std Dev  Doc Count  Negative  Positive  \\\n",
       "0        1.240000e-08  3.560000e-06         84         0         0   \n",
       "1        9.730000e-12  9.860000e-09          1         0         0   \n",
       "2        1.390000e-10  6.230000e-08          7         0         0   \n",
       "3        3.160000e-10  9.380000e-08         12         0         0   \n",
       "4        3.680000e-07  3.370000e-05        914         0         0   \n",
       "\n",
       "   Uncertainty  Litigious  Constraining  Superfluous  Interesting  Modal  \\\n",
       "0            0          0             0            0            0      0   \n",
       "1            0          0             0            0            0      0   \n",
       "2            0          0             0            0            0      0   \n",
       "3            0          0             0            0            0      0   \n",
       "4            0          0             0            0            0      0   \n",
       "\n",
       "   Irr_Verb  Harvard_IV  Syllables     Source  \n",
       "0         0           0          2  12of12inf  \n",
       "1         0           0          2  12of12inf  \n",
       "2         0           0          3  12of12inf  \n",
       "3         0           0          2  12of12inf  \n",
       "4         0           0          3  12of12inf  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = pd.read_csv('LoughranMcDonald_MasterDictionary_2018.csv')\n",
    "word_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 2009, 2011, 2014, 2012])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict.Negative.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 2009, 2012, 2011])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict.Positive.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From logically analysing, the words corresponding to which the fields in the `Positive` and `Negative` columns are not zero, are hence positive and negative words respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words = word_dict.Word[word_dict.Negative != 0]\n",
    "neg_words = list(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = word_dict.Word[word_dict.Positive != 0]\n",
    "pos_words = list(pos_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lower(word_list):\n",
    "    new_word_list = []\n",
    "    for word in word_list:\n",
    "        new_word_list.append(word.lower())\n",
    "    return new_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = make_lower(pos_words)\n",
    "neg_words = make_lower(neg_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Derived Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text ought to be tokenised first for efficient recognition (using the `nltk` library). Then the first two directly derived metrics can be calculated: Positive score and Negative score. First, I will try a specific case, and then I will try to generalise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = corpus['0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive score = 12\n",
      "Negative score = 16\n"
     ]
    }
   ],
   "source": [
    "positive_score, negative_score = 0, 0\n",
    "for token in tokens:\n",
    "    if token in pos_words:\n",
    "        positive_score += 1\n",
    "    if token in neg_words:\n",
    "        negative_score -= 1\n",
    "negative_score = -negative_score\n",
    "print(\"Positive score = \" + str(positive_score))\n",
    "print(\"Negative score = \" + str(negative_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, polarity and subjectivity scores can be calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity score = -0.14285713775510223\n",
      "Subjectivity score = 0.03305785120064008\n"
     ]
    }
   ],
   "source": [
    "polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "subjectivity_score = (positive_score + negative_score) / (len(tokens) + 0.000001)\n",
    "print(\"Polarity score = \"+ str(polarity_score))\n",
    "print(\"Subjectivity score = \" + str(subjectivity_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Score Categorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A text is classified as:\n",
    "1. Most negative if polarity is below -0.5\n",
    "2. Negative if polarity is between -0.5 and 0\n",
    "3. Neutral if polarity is 0\n",
    "4. Positive if polarity is between 0 and 0.5\n",
    "5. Most positive if polarity is above 0.5\n",
    "\n",
    "in the range (-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pos_neg_score(tokens):\n",
    "    positive_score, negative_score = 0, 0\n",
    "    for token in tokens:\n",
    "        if token in pos_words:\n",
    "            positive_score += 1\n",
    "        if token in neg_words:\n",
    "            negative_score += 1\n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "    pos_word_prop = positive_score / len(tokens)\n",
    "    neg_word_prop = negative_score / len(tokens)\n",
    "    return positive_score, negative_score, polarity_score, pos_word_prop, neg_word_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_positive_score, mda_negative_score, mda_polarity_score = [], [], []\n",
    "mda_positive_word_proportion, mda_negative_word_proportion = [], []\n",
    "\n",
    "for mda in corpus['0']:\n",
    "    tokens = word_tokenize(str(mda))\n",
    "    positive_score, negative_score, polarity_score, pos_word_prop, neg_word_prop = find_pos_neg_score(tokens)\n",
    "    mda_positive_score.append(positive_score)\n",
    "    mda_negative_score.append(negative_score)\n",
    "    mda_polarity_score.append(polarity_score)\n",
    "    mda_positive_word_proportion.append(pos_word_prop)\n",
    "    mda_negative_word_proportion.append(neg_word_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqdmr_positive_score, qqdmr_negative_score, qqdmr_polarity_score = [], [], []\n",
    "qqdmr_positive_word_proportion, qqdmr_negative_word_proportion = [], []\n",
    "\n",
    "for qqdmr in corpus['1']:\n",
    "    tokens = word_tokenize(str(qqdmr))\n",
    "    positive_score, negative_score, polarity_score, pos_word_prop, neg_word_prop = find_pos_neg_score(tokens)\n",
    "    qqdmr_positive_score.append(positive_score)\n",
    "    qqdmr_negative_score.append(negative_score)\n",
    "    qqdmr_polarity_score.append(polarity_score)\n",
    "    qqdmr_positive_word_proportion.append(pos_word_prop)\n",
    "    qqdmr_negative_word_proportion.append(neg_word_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_positive_score, rf_negative_score, rf_polarity_score = [], [], []\n",
    "rf_positive_word_proportion, rf_negative_word_proportion = [], []\n",
    "\n",
    "for rf in corpus['2']:\n",
    "    tokens = word_tokenize(str(rf))\n",
    "    positive_score, negative_score, polarity_score, pos_word_prop, neg_word_prop = find_pos_neg_score(tokens)\n",
    "    rf_positive_score.append(positive_score)\n",
    "    rf_negative_score.append(negative_score)\n",
    "    rf_polarity_score.append(polarity_score)\n",
    "    rf_positive_word_proportion.append(pos_word_prop)\n",
    "    rf_negative_word_proportion.append(neg_word_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis of Readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readability analysis metrics are average sentence length, percentage of complex words and fog index. Again, I will take a specific case for understandability and generalise after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the average sentence length, total number of words and sentences are required per text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "text = corpus['0'][0]\n",
    "words = text.split()\n",
    "sentences = text.split('.')\n",
    "print(len(words))\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Derived Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentence Length: 13.962962962962964\n"
     ]
    }
   ],
   "source": [
    "avg_sentence_len = len(words) / len(sentences)\n",
    "print(\"Average Sentence Length: \" + str(avg_sentence_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the percentage of complex words, one ought to find the number of complex words in a text. Complex words are the ones which have more than two syllables. This can be done using `TextStat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat.textstat import textstatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508\n"
     ]
    }
   ],
   "source": [
    "num_complex_words = 0\n",
    "for word in words:\n",
    "    syllables = textstatistics().syllable_count(word)\n",
    "    if syllables >= 2:\n",
    "        num_complex_words += 1\n",
    "print(num_complex_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Complex words = 0.6737400530503979\n"
     ]
    }
   ],
   "source": [
    "perc_complex_words = num_complex_words / len(words)\n",
    "print(\"Percentage of Complex words = \"+ str(perc_complex_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fog index = 5.8546812064053455\n"
     ]
    }
   ],
   "source": [
    "fog_index = 0.4 * (avg_sentence_len + perc_complex_words)\n",
    "print(\"Fog index = \"+ str(fog_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complex_words(words):\n",
    "    num_complex_words = 0\n",
    "    for word in words:\n",
    "        syllables = textstatistics().syllable_count(word)\n",
    "        if syllables >= 2:\n",
    "            num_complex_words += 1\n",
    "    return num_complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_read_metrics(words, sentences):\n",
    "    avg_sentence_len = len(words) / len(sentences)\n",
    "    num_complex_words = get_complex_words(words)\n",
    "    perc_complex_words = num_complex_words / len(words)\n",
    "    fog_index = 0.4 * (avg_sentence_len + perc_complex_words)\n",
    "    return avg_sentence_len, perc_complex_words, fog_index, len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_average_sentence_length, mda_percentage_of_complex_words = [], []\n",
    "mda_fog_index, mda_complex_word_count = [], []\n",
    "mda_word_count = []\n",
    "\n",
    "for text in corpus['0']:\n",
    "    words = str(text).split(); sentences = str(text).split('.')\n",
    "    avg_sentence_len, perc_complex_words, fog_index, num_words = calc_read_metrics(words, sentences)\n",
    "    num_complex_words = get_complex_words(words)\n",
    "    \n",
    "    mda_average_sentence_length.append(avg_sentence_len)\n",
    "    mda_percentage_of_complex_words.append(perc_complex_words)\n",
    "    mda_fog_index.append(fog_index)\n",
    "    mda_complex_word_count.append(num_complex_words)\n",
    "    mda_word_count.append(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqdmr_average_sentence_length, qqdmr_percentage_of_complex_words = [], []\n",
    "qqdmr_fog_index, qqdmr_complex_word_count = [], []\n",
    "qqdmr_word_count = []\n",
    "\n",
    "for text in corpus['1']:\n",
    "    words = str(text).split(); sentences = str(text).split('.')\n",
    "    avg_sentence_len, perc_complex_words, fog_index, num_words = calc_read_metrics(words, sentences)\n",
    "    num_complex_words = get_complex_words(words)\n",
    "    \n",
    "    qqdmr_average_sentence_length.append(avg_sentence_len)\n",
    "    qqdmr_percentage_of_complex_words.append(perc_complex_words)\n",
    "    qqdmr_fog_index.append(fog_index)\n",
    "    qqdmr_complex_word_count.append(num_complex_words)\n",
    "    qqdmr_word_count.append(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_average_sentence_length, rf_percentage_of_complex_words = [], []\n",
    "rf_fog_index, rf_complex_word_count = [], []\n",
    "rf_word_count = []\n",
    "\n",
    "for text in corpus['2']:\n",
    "    words = str(text).split(); sentences = str(text).split('.')\n",
    "    avg_sentence_len, perc_complex_words, fog_index, num_words = calc_read_metrics(words, sentences)\n",
    "    num_complex_words = get_complex_words(words)\n",
    "    \n",
    "    rf_average_sentence_length.append(avg_sentence_len)\n",
    "    rf_percentage_of_complex_words.append(perc_complex_words)\n",
    "    rf_fog_index.append(fog_index)\n",
    "    rf_complex_word_count.append(num_complex_words)\n",
    "    rf_word_count.append(num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis of Words of Uncertaintly and Constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uncertain and constraining words are as given in the `uncertainty_dictionary.xlsx` and `constraining_dictionary.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertain = pd.read_csv('instructions/uncertainty_dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraining = pd.read_csv('instructions/constraining_dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ABEYANCE\n",
       "1      ABEYANCES\n",
       "2         ALMOST\n",
       "3     ALTERATION\n",
       "4    ALTERATIONS\n",
       "Name: Word, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertain = uncertain['Word']\n",
    "uncertain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertain = list(uncertain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ABIDE\n",
       "1    ABIDING\n",
       "2      BOUND\n",
       "3    BOUNDED\n",
       "4     COMMIT\n",
       "Name: Word, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constrain = constraining['Word']\n",
    "constrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "constrain = list(constrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertain = make_lower(uncertain)\n",
    "constrain = make_lower(constrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Derived Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncertain_constrain(text):\n",
    "    uncertain_score, constrain_score = 0, 0\n",
    "    for word in str(text).split():\n",
    "        if word in uncertain:\n",
    "            uncertain_score += 1\n",
    "        if word in constrain:\n",
    "            constrain_score += 1\n",
    "    uncertain_prop = uncertain_score / len(str(text).split())\n",
    "    constrain_prop = constrain_score / len(str(text).split())\n",
    "    return uncertain_score, constrain_score, uncertain_prop, constrain_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_uncertainty_score, mda_constraining_score = [], []\n",
    "mda_uncertainty_word_proportion, mda_constraining_word_proportion = [], []\n",
    "\n",
    "for text in corpus['0']:\n",
    "    uncertain_score, constrain_score, uncertain_prop, constrain_prop = get_uncertain_constrain(text)\n",
    "    \n",
    "    mda_uncertainty_score.append(uncertain_score)\n",
    "    mda_constraining_score.append(constrain_score)\n",
    "    mda_uncertainty_word_proportion.append(uncertain_prop)\n",
    "    mda_constraining_word_proportion.append(constrain_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqdmr_uncertainty_score, qqdmr_constraining_score = [], []\n",
    "qqdmr_uncertainty_word_proportion, qqdmr_constraining_word_proportion = [], []\n",
    "\n",
    "for text in corpus['1']:\n",
    "    uncertain_score, constrain_score, uncertain_prop, constrain_prop = get_uncertain_constrain(text)\n",
    "    \n",
    "    qqdmr_uncertainty_score.append(uncertain_score)\n",
    "    qqdmr_constraining_score.append(constrain_score)\n",
    "    qqdmr_uncertainty_word_proportion.append(uncertain_prop)\n",
    "    qqdmr_constraining_word_proportion.append(constrain_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_uncertainty_score, rf_constraining_score = [], []\n",
    "rf_uncertainty_word_proportion, rf_constraining_word_proportion = [], []\n",
    "\n",
    "for text in corpus['2']:\n",
    "    uncertain_score, constrain_score, uncertain_prop, constrain_prop = get_uncertain_constrain(text)\n",
    "    \n",
    "    rf_uncertainty_score.append(uncertain_score)\n",
    "    rf_constraining_score.append(constrain_score)\n",
    "    rf_uncertainty_word_proportion.append(uncertain_prop)\n",
    "    rf_constraining_word_proportion.append(constrain_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All but one variables have been extracted. It is the number of constraining words present throughout the report instead of any particular section. Since I stored only a few sections of all reports, I must scrape the urls again, but I can try to find constraining words without storing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('corpus.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt</th>\n",
       "      <td>'item 7. management\\'s discussion  analysis  f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-001001.txt</th>\n",
       "      <td>\"item 2. management's discussion  analysis  fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.sec.gov/Archives/edgar/data/3662/0000950172-98-000783.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-002145.txt</th>\n",
       "      <td>'item 7. management\\'s discussion  analysis  f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.sec.gov/Archives/edgar/data/3662/0000950172-98-001203.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    0  \\\n",
       "https://www.sec.gov/Archives/edgar/data/3662/00...  'item 7. management\\'s discussion  analysis  f...   \n",
       "https://www.sec.gov/Archives/edgar/data/3662/00...  \"item 2. management's discussion  analysis  fi...   \n",
       "https://www.sec.gov/Archives/edgar/data/3662/00...                                                NaN   \n",
       "https://www.sec.gov/Archives/edgar/data/3662/00...  'item 7. management\\'s discussion  analysis  f...   \n",
       "https://www.sec.gov/Archives/edgar/data/3662/00...                                                NaN   \n",
       "\n",
       "                                                      1   2  \n",
       "https://www.sec.gov/Archives/edgar/data/3662/00...  NaN NaN  \n",
       "https://www.sec.gov/Archives/edgar/data/3662/00...  NaN NaN  \n",
       "https://www.sec.gov/Archives/edgar/data/3662/00...  NaN NaN  \n",
       "https://www.sec.gov/Archives/edgar/data/3662/00...  NaN NaN  \n",
       "https://www.sec.gov/Archives/edgar/data/3662/00...  NaN NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-001001.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950172-98-000783.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-002145.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950172-98-001203.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-002278.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-002401.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-002402.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950172-99-000362.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-99-000775.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950172-99-000584.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-99-001005.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950172-99-001074.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-99-001361.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000889812-99-003241.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-99-001639.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-99-001640.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950172-99-001626.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3662/0000950170-99-001856.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-06-002926.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-06-004690.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-06-005244.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-06-007243.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-06-007244.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-06-007871.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-06-009522.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950134-06-023819.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-07-001381.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-07-002432.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-07-003918.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-07-005361.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-08-001569.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/3982/0000950129-08-002507.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4447/0000950123-03-012528.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4447/0000950123-04-003250.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4447/0000950123-04-003322.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4447/0000950123-04-005950.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4447/0000950123-04-009350.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4447/0000950123-04-013054.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4447/0000950123-05-003078.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4447/0000950123-05-005767.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4447/0000950123-05-009475.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4447/0000950123-05-013153.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4457/0000004457-99-000043.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4457/0000004457-00-000018.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4457/0000004457-00-000067.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4457/0000004457-00-000080.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4457/0000004457-00-000105.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4457/0000004457-01-500024.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4457/0000004457-01-500063.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4457/0000004457-01-500060.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4457/0000004457-01-500081.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4457/0000004457-01-500083.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4515/0000004515-08-000073.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4515/0000004515-09-000008.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4515/0000004515-09-000018.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4515/0000004515-09-000029.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4515/0000004515-09-000039.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4515/0000004515-09-000041.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4515/0000004515-10-000006.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4515/0000004515-10-000016.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4515/0000950123-10-066865.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4515/0000950123-10-094615.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4962/0001193125-14-167067.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/4962/0001193125-14-286961.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5588/0000930661-96-001510.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5588/0000950134-97-002428.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5588/0000950134-97-003934.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5588/0000950134-97-006223.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5588/0000950134-97-008577.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5588/0000950134-98-002477.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5588/0000950134-98-004241.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5588/0000950134-98-006988.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5588/0000005588-98-000008.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5588/0000005588-98-000010.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000005907-99-000027.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000005907-99-000037.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000005907-00-000014.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000005907-00-000025.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000005907-00-000031.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000005907-00-000038.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000005907-01-000002.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000005907-01-000012.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000005907-01-000015.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000950123-01-502538.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000950123-01-504075.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000950123-01-505366.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/5907/0000950123-01-505598.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6071/0000006071-98-000023.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6071/0000006071-98-000026.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6071/0000889812-99-001116.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6071/0000006071-99-000013.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6071/0000006071-99-000015.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6071/0000006071-99-000017.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6071/0000006071-00-000002.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6071/0000006071-00-000011.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-99-000023.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-99-000028.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000950134-00-002454.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-00-000009.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000950134-00-006067.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-00-000017.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000950134-01-002483.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000950134-01-500665.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-01-500032.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-01-500047.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000950134-02-001661.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-02-000015.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-02-000035.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-02-000052.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000950134-02-012680.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000950134-02-012682.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-03-000012.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0001047469-03-013301.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-03-000030.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-03-000045.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-08-000060.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-09-000009.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-09-000016.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-09-000029.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-09-000038.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-09-000040.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-10-000006.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000006201-10-000013.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000950123-10-066894.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6201/0000950123-10-094605.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6260/0000006260-94-000014.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6260/0000006260-94-000016.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6260/0000006260-97-000011.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6260/0000006260-98-000001.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6260/0000006260-98-000003.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6260/0000914121-98-000672.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6260/0001047469-98-045227.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6260/0000006260-99-000005.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6260/0000006260-99-000007.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/6260/0000006260-99-000010.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/11860/0000011860-98-000022.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/11860/0001021408-99-000543.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/11860/0000011860-99-000025.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/11860/0000011860-99-000030.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/11860/0000011860-99-000035.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/11860/0000011860-99-000042.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/11860/0000011860-00-000019.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/11860/0000011860-00-000022.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/11860/0000011860-00-000025.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/11860/0000011860-00-000028.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/11860/0000011860-00-000038.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/12239/0001104659-07-024804.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/12239/0001104659-07-040463.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/12239/0001104659-07-041441.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/12239/0001104659-07-042333.txt\n",
      "Processed https://www.sec.gov/Archives/edgar/data/12239/0001104659-07-062470.txt\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "constraining_words_whole_report = []\n",
    "for url in corpus.index:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    soup = str(soup).lower()\n",
    "    \n",
    "    _, constraining_words, _, _ = get_uncertain_constrain(soup)\n",
    "    constraining_words_whole_report.append(constraining_words)\n",
    "    \n",
    "    print(\"Processed \" + url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>3/6/98</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>5/15/98</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>8/13/98</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>11/12/98</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>11/16/98</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO     FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803    3/6/98  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805   5/15/98     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808   8/13/98  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811  11/12/98   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811  11/16/98  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  \n",
       "0  edgar/data/3662/0000950170-98-000413.txt  \n",
       "1  edgar/data/3662/0000950170-98-001001.txt  \n",
       "2  edgar/data/3662/0000950172-98-000783.txt  \n",
       "3  edgar/data/3662/0000950170-98-002145.txt  \n",
       "4  edgar/data/3662/0000950172-98-001203.txt  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.read_csv('instructions/cik_list.csv')\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['mda_positive_score'] = mda_positive_score\n",
    "output['mda_negative_score'] = mda_negative_score\n",
    "output['mda_polarity_score'] = mda_polarity_score\n",
    "output['mda_average_sentence_length'] = mda_average_sentence_length\n",
    "output['mda_percentage_of_complex_words'] = mda_percentage_of_complex_words\n",
    "output['mda_fog_index'] = mda_fog_index\n",
    "output['mda_complex_word_count'] = mda_complex_word_count\n",
    "output['mda_word_count'] = mda_word_count\n",
    "output['mda_uncertainty_score'] = mda_uncertainty_score\n",
    "output['mda_constraining_score'] = mda_constraining_score\n",
    "output['mda_positive_word_proportion'] = mda_positive_word_proportion\n",
    "output['mda_negative_word_proportion'] = mda_negative_word_proportion\n",
    "output['mda_uncertainty_word_proportion'] = mda_uncertainty_word_proportion\n",
    "output['mda_constraining_word_proportion'] = mda_constraining_word_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>mda_positive_score</th>\n",
       "      <th>mda_negative_score</th>\n",
       "      <th>mda_polarity_score</th>\n",
       "      <th>mda_average_sentence_length</th>\n",
       "      <th>mda_percentage_of_complex_words</th>\n",
       "      <th>mda_fog_index</th>\n",
       "      <th>mda_complex_word_count</th>\n",
       "      <th>mda_word_count</th>\n",
       "      <th>mda_uncertainty_score</th>\n",
       "      <th>mda_constraining_score</th>\n",
       "      <th>mda_positive_word_proportion</th>\n",
       "      <th>mda_negative_word_proportion</th>\n",
       "      <th>mda_uncertainty_word_proportion</th>\n",
       "      <th>mda_constraining_word_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>3/6/98</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>13.962963</td>\n",
       "      <td>0.673740</td>\n",
       "      <td>5.854681</td>\n",
       "      <td>508</td>\n",
       "      <td>754</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014168</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.001326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>5/15/98</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>8.545455</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>3.647969</td>\n",
       "      <td>54</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>8/13/98</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>11/12/98</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.744681</td>\n",
       "      <td>0.854737</td>\n",
       "      <td>0.580049</td>\n",
       "      <td>0.573914</td>\n",
       "      <td>471</td>\n",
       "      <td>812</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>0.013547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>11/16/98</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO     FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803    3/6/98  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805   5/15/98     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808   8/13/98  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811  11/12/98   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811  11/16/98  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  mda_positive_score  \\\n",
       "0  edgar/data/3662/0000950170-98-000413.txt                  12   \n",
       "1  edgar/data/3662/0000950170-98-001001.txt                   0   \n",
       "2  edgar/data/3662/0000950172-98-000783.txt                   0   \n",
       "3  edgar/data/3662/0000950170-98-002145.txt                   6   \n",
       "4  edgar/data/3662/0000950172-98-001203.txt                   0   \n",
       "\n",
       "   mda_negative_score  mda_polarity_score  mda_average_sentence_length  \\\n",
       "0                  16           -0.142857                    13.962963   \n",
       "1                   3           -1.000000                     8.545455   \n",
       "2                   0            0.000000                     1.000000   \n",
       "3                  41           -0.744681                     0.854737   \n",
       "4                   0            0.000000                     1.000000   \n",
       "\n",
       "   mda_percentage_of_complex_words  mda_fog_index  mda_complex_word_count  \\\n",
       "0                         0.673740       5.854681                     508   \n",
       "1                         0.574468       3.647969                      54   \n",
       "2                         0.000000       0.400000                       0   \n",
       "3                         0.580049       0.573914                     471   \n",
       "4                         0.000000       0.400000                       0   \n",
       "\n",
       "   mda_word_count  mda_uncertainty_score  mda_constraining_score  \\\n",
       "0             754                      4                       1   \n",
       "1              94                      1                       0   \n",
       "2               1                      0                       0   \n",
       "3             812                      5                      11   \n",
       "4               1                      0                       0   \n",
       "\n",
       "   mda_positive_word_proportion  mda_negative_word_proportion  \\\n",
       "0                      0.014168                      0.018890   \n",
       "1                      0.000000                      0.027523   \n",
       "2                      0.000000                      0.000000   \n",
       "3                      0.004501                      0.030758   \n",
       "4                      0.000000                      0.000000   \n",
       "\n",
       "   mda_uncertainty_word_proportion  mda_constraining_word_proportion  \n",
       "0                         0.005305                          0.001326  \n",
       "1                         0.010638                          0.000000  \n",
       "2                         0.000000                          0.000000  \n",
       "3                         0.006158                          0.013547  \n",
       "4                         0.000000                          0.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['qqdmr_positive_score'] = qqdmr_positive_score\n",
    "output['qqdmr_negative_score'] = qqdmr_negative_score\n",
    "output['qqdmr_polarity_score'] = qqdmr_polarity_score\n",
    "output['qqdmr_average_sentence_length'] = qqdmr_average_sentence_length\n",
    "output['qqdmr_percentage_of_complex_words'] = qqdmr_percentage_of_complex_words\n",
    "output['qqdmr_fog_index'] = qqdmr_fog_index\n",
    "output['qqdmr_complex_word_count'] = qqdmr_complex_word_count\n",
    "output['qqdmr_word_count'] = qqdmr_word_count\n",
    "output['qqdmr_uncertainty_score'] = qqdmr_uncertainty_score\n",
    "output['qqdmr_constraining_score'] = qqdmr_constraining_score\n",
    "output['qqdmr_positive_word_proportion'] = qqdmr_positive_word_proportion\n",
    "output['qqdmr_negative_word_proportion'] = qqdmr_negative_word_proportion\n",
    "output['qqdmr_uncertainty_word_proportion'] = qqdmr_uncertainty_word_proportion\n",
    "output['qqdmr_constraining_word_proportion'] = qqdmr_constraining_word_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 34)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['rf_positive_score'] = rf_positive_score\n",
    "output['rf_negative_score'] = rf_negative_score\n",
    "output['rf_polarity_score'] = rf_polarity_score\n",
    "output['rf_average_sentence_length'] = rf_average_sentence_length\n",
    "output['rf_percentage_of_complex_words'] = rf_percentage_of_complex_words\n",
    "output['rf_fog_index'] = rf_fog_index\n",
    "output['rf_complex_word_count'] = rf_complex_word_count\n",
    "output['rf_word_count'] = rf_word_count\n",
    "output['rf_uncertainty_score'] = rf_uncertainty_score\n",
    "output['rf_constraining_score'] = rf_constraining_score\n",
    "output['rf_positive_word_proportion'] = rf_positive_word_proportion\n",
    "output['rf_negative_word_proportion'] = rf_negative_word_proportion\n",
    "output['rf_uncertainty_word_proportion'] = rf_uncertainty_word_proportion\n",
    "output['rf_constraining_word_proportion'] = rf_constraining_word_proportion\n",
    "output['constraining_words_whole_report'] = constraining_words_whole_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>mda_positive_score</th>\n",
       "      <th>mda_negative_score</th>\n",
       "      <th>mda_polarity_score</th>\n",
       "      <th>mda_average_sentence_length</th>\n",
       "      <th>...</th>\n",
       "      <th>rf_fog_index</th>\n",
       "      <th>rf_complex_word_count</th>\n",
       "      <th>rf_word_count</th>\n",
       "      <th>rf_uncertainty_score</th>\n",
       "      <th>rf_constraining_score</th>\n",
       "      <th>rf_positive_word_proportion</th>\n",
       "      <th>rf_negative_word_proportion</th>\n",
       "      <th>rf_uncertainty_word_proportion</th>\n",
       "      <th>rf_constraining_word_proportion</th>\n",
       "      <th>constraining_words_whole_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>3/6/98</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>13.962963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>5/15/98</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>8.545455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>8/13/98</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>11/12/98</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.744681</td>\n",
       "      <td>0.854737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>11/16/98</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO     FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803    3/6/98  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805   5/15/98     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808   8/13/98  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811  11/12/98   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811  11/16/98  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  mda_positive_score  \\\n",
       "0  edgar/data/3662/0000950170-98-000413.txt                  12   \n",
       "1  edgar/data/3662/0000950170-98-001001.txt                   0   \n",
       "2  edgar/data/3662/0000950172-98-000783.txt                   0   \n",
       "3  edgar/data/3662/0000950170-98-002145.txt                   6   \n",
       "4  edgar/data/3662/0000950172-98-001203.txt                   0   \n",
       "\n",
       "   mda_negative_score  mda_polarity_score  mda_average_sentence_length  ...  \\\n",
       "0                  16           -0.142857                    13.962963  ...   \n",
       "1                   3           -1.000000                     8.545455  ...   \n",
       "2                   0            0.000000                     1.000000  ...   \n",
       "3                  41           -0.744681                     0.854737  ...   \n",
       "4                   0            0.000000                     1.000000  ...   \n",
       "\n",
       "   rf_fog_index  rf_complex_word_count  rf_word_count  rf_uncertainty_score  \\\n",
       "0           0.4                      0              1                     0   \n",
       "1           0.4                      0              1                     0   \n",
       "2           0.4                      0              1                     0   \n",
       "3           0.4                      0              1                     0   \n",
       "4           0.4                      0              1                     0   \n",
       "\n",
       "   rf_constraining_score  rf_positive_word_proportion  \\\n",
       "0                      0                          0.0   \n",
       "1                      0                          0.0   \n",
       "2                      0                          0.0   \n",
       "3                      0                          0.0   \n",
       "4                      0                          0.0   \n",
       "\n",
       "   rf_negative_word_proportion  rf_uncertainty_word_proportion  \\\n",
       "0                          0.0                             0.0   \n",
       "1                          0.0                             0.0   \n",
       "2                          0.0                             0.0   \n",
       "3                          0.0                             0.0   \n",
       "4                          0.0                             0.0   \n",
       "\n",
       "   rf_constraining_word_proportion  constraining_words_whole_report  \n",
       "0                              0.0                             1333  \n",
       "1                              0.0                              916  \n",
       "2                              0.0                                5  \n",
       "3                              0.0                              642  \n",
       "4                              0.0                                4  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
